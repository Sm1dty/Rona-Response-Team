{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minnesota State COVID Response Analysis\n",
    "This notebook contains the work to identify associations between the Minnesota state governmental response and the COVID-19 case count throughout the pandemic.\n",
    "\n",
    "\n",
    "## Data Cleanup\n",
    "As with most data mining projects, we will need to clean up the given data file in order to focus on the goal at hand. The \"all-states-history.csv\" file is a dataset of U.S. COVID-19 cases and deaths dating from the start of the pandemic to 11/29/20 and was sourced from [The Covid Tracking Project](https://covidtracking.com/data). We are analyzing 3 periods throughout this timeline:\n",
    "\n",
    "- Early Breakout (Early March -> May)\n",
    "- Summer (June -> August)\n",
    "- Fall/Present (September -> Late November)\n",
    "\n",
    "We will divide up the data into 3 different frames according to these periods.\n",
    "\n",
    "In order to analyze with state policy actions, we will merge data from the [Oxford Covid-19 Government Response Tracker](https://github.com/OxCGRT/covid-policy-tracker) github dataset titled 'state-policies.csv'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVID tracking project data\n",
    "covid_data = pd.read_csv('all-states-history.csv')\n",
    "\n",
    "# state plicy data\n",
    "policy_data = pd.read_csv('state-policies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up Covid data to only include Minnesota instances and the appropriate attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating the columns we need\n",
    "columns_to_show = ['date','state','death','deathConfirmed','deathIncrease','hospitalized','hospitalizedIncrease','negative'\n",
    "                   ,'negativeIncrease','positive','positiveIncrease','totalTestResults','totalTestResultsIncrease']\n",
    "\n",
    "#isolating only for MN data and putting in order March->November\n",
    "covid_clean_data = covid_data[covid_data['state'] == 'MN']\n",
    "covid_clean_data = covid_clean_data[columns_to_show]\n",
    "covid_clean_data = covid_clean_data.iloc[::-1]\n",
    "\n",
    "#reindexing for weekly processing \n",
    "covid_clean_data['date'] = covid_clean_data['date'].astype('datetime64[ns]')\n",
    "covid_clean_data = covid_clean_data.set_index('date')\n",
    "\n",
    "# isolating the columns that need to be summed when converting to weekly index\n",
    "columns_to_sum = covid_clean_data[['deathIncrease','hospitalizedIncrease','negativeIncrease','positiveIncrease','totalTestResultsIncrease']]\n",
    "weekly_data = columns_to_sum.resample('W', label='right', closed='right').sum()\n",
    "weekly_data = weekly_data.reset_index()\n",
    "\n",
    "# converting remaining non-sum columns to weekly index\n",
    "remaining_cols = covid_clean_data[['state','death','deathConfirmed','hospitalized', 'negative','positive','totalTestResults']]\n",
    "remaining_cols = remaining_cols.resample('W').backfill().reset_index()\n",
    "remaining_cols.head(39)\n",
    "\n",
    "#merging and resetting the datframe order to be more clear\n",
    "covid_clean_data = pd.merge(remaining_cols, weekly_data, on='date').fillna(0)\n",
    "covid_clean_data = covid_clean_data[['date','state','death','deathIncrease','deathConfirmed','hospitalized', 'hospitalizedIncrease','negative',\n",
    "                        'negativeIncrease','positive', 'positiveIncrease','totalTestResults','totalTestResultsIncrease']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up state policy dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating data only about the current state of interest, Minnesota\n",
    "policy_clean_data = policy_data[policy_data['RegionName'] == 'Minnesota']\n",
    "#deleting rows whose dates are outside of the scope of this project\n",
    "policy_clean_data = policy_clean_data.iloc[60:] #delete the first 60 rows due to their January - February dates\n",
    "policy_clean_data = policy_clean_data.iloc[:-3,] #as well as the last 3 rows due to their December dates\n",
    "\n",
    "#declaring and extracting columns of interest from the original dataset\n",
    "columns_of_interest = ['RegionName', 'Jurisdiction', 'Date', 'C1_School closing', 'C2_Workplace closing', \n",
    "                       'C3_Cancel public events', 'C6_Stay at home requirements', \n",
    "                       'C7_Restrictions on internal movement', 'C8_International travel controls', \n",
    "                       'H1_Public information campaigns', 'H2_Testing policy', 'H3_Contact tracing', \n",
    "                       'H4_Emergency investment in healthcare', 'H5_Investment in vaccines', \n",
    "                       'H6_Facial Coverings', 'M1_Wildcard']\n",
    "policy_clean_data = policy_clean_data[columns_of_interest]\n",
    "\n",
    "# reformating date section\n",
    "policy_clean_data = policy_clean_data.reset_index(drop = True)\n",
    "from datetime import datetime as dt\n",
    "\n",
    "for i in range(policy_clean_data.shape[0]):\n",
    "    date_string = str(policy_clean_data['Date'][i])\n",
    "    policy_clean_data['Date'][i] = dt.strptime(date_string, \"%Y%m%d\").date()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Breaking down clean data into each period (earliest days at bottom of dataset)\n",
    "\n",
    "early_breakout_data = clean_data[0:13]\n",
    "\n",
    "summer_data = clean_data[13:26]\n",
    "\n",
    "fall_data = clean_data[26:]\n",
    "\n",
    "early_breakout_data.head(13)\n",
    "\n",
    "bins = pd.cut(early_breakout_data['positiveIncrease'],4)\n",
    "\n",
    "print(bins.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Important MN Stats:\n",
    "\n",
    "- Population (mn.gov estimate): 5,680,337\n",
    "- Land Area (estimate): 79,610.08 sq. mi.\n",
    "- Population Density: 71.35 people/sq. mi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are performing a market basket analysis using the Apriori algorithm, we will need to discretize the data. To do so, we've implemented a function 'discretize_data':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr is the dataframe \n",
    "# k is the number of equal frequency bins\n",
    "def discretize_data(arr, k):\n",
    "    out = pd.DataFrame({'date': arr['date']})\n",
    "    out['state'] = arr['state']\n",
    "    cols = arr.columns[2:]\n",
    "    for i in cols:\n",
    "        bins = pd.cut(arr[i], k, 'retbins' == True, labels = list(range(k)))\n",
    "        bin_range = pd.cut(arr[i],k)\n",
    "        for j in range(k):\n",
    "            count = 0\n",
    "            for row in arr.index:\n",
    "                if bins.loc[row] == j:\n",
    "                    out.loc[row, i + \" bin \" +  str(bin_range.loc[count])] = 1\n",
    "                count += 1\n",
    "    out = out.fillna(0)\n",
    "    return out      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Breakout Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_break_disc = discretize_data(early_breakout_data,4)\n",
    "early_break_disc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
