{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California State COVID Response Analysis\n",
    "This notebook contains the work to identify associations between the California state governmental response and the COVID-19 case count throughout the pandemic.\n",
    "\n",
    "\n",
    "## Data Cleanup\n",
    "As with most data mining projects, we will need to clean up the given data file in order to focus on the goal at hand. The \"all-states-history.csv\" file is a dataset of U.S. COVID-19 cases and deaths dating from the start of the pandemic to 11/29/20 and was sourced from [The Covid Tracking Project](https://covidtracking.com/data). We are analyzing 3 periods throughout this timeline:\n",
    "\n",
    "- Early Breakout (Early March -> May)\n",
    "- Summer (June -> August)\n",
    "- Fall/Present (September -> Late November)\n",
    "\n",
    "We will divide up the data into 3 different frames according to these periods.\n",
    "\n",
    "In order to analyze with state policy actions, we will merge data from the [Oxford Covid-19 Government Response Tracker](https://github.com/OxCGRT/covid-policy-tracker) github dataset titled 'state-policies.csv'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "import seaborn as sns\n",
    "\n",
    "# for market basket analysis\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to a way to discretize and format data too be suitable for apriori analysis. The function below will discretize the necessary columns into bins and set the values to strings according to the bin they are placed in.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_data(arr, k):\n",
    "    cols = arr.columns\n",
    "    for i in cols:\n",
    "        bin_range = pd.cut(arr[i],k)\n",
    "        col_copy = arr[i].astype('str')\n",
    "        for j in range(len(col_copy)):\n",
    "            col_copy[j] = i + \"\" +str(bin_range[j])\n",
    "            \n",
    "        arr[i] = col_copy   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVID tracking project data\n",
    "covid_data = pd.read_csv('all-states-history.csv')\n",
    "\n",
    "# state plicy data\n",
    "policy_data = pd.read_csv('state-policies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up Covid data to only include California instances and the appropriate attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating the columns we need\n",
    "columns_to_show = ['date','deathIncrease','hospitalizedIncrease','negativeIncrease','positiveIncrease','totalTestResultsIncrease']\n",
    "\n",
    "#isolating only CA data and putting in order March->November\n",
    "covid_clean_data = covid_data[covid_data['state'] == 'CA']\n",
    "covid_clean_data = covid_clean_data[columns_to_show]\n",
    "covid_clean_data = covid_clean_data.iloc[::-1]\n",
    "covid_clean_data = covid_clean_data.reset_index(drop = True).fillna(0)\n",
    "\n",
    "#Now we can divide up the covid data into the 3 distinct periods (as well as keep a dataframe for the overall period)\n",
    "# getting start and end dates for dividing up into periods\n",
    "\n",
    "EB_start = dt.strptime(covid_clean_data['date'][0],\"%Y-%m-%d\")\n",
    "EB_end = dt.strptime(\"2020-05-31\", \"%Y-%m-%d\")\n",
    "\n",
    "S_start = dt.strptime(\"2020-06-01\", \"%Y-%m-%d\")\n",
    "S_end = dt.strptime(\"2020-08-31\", \"%Y-%m-%d\") \n",
    "\n",
    "FP_start = dt.strptime(\"2020-09-01\", \"%Y-%m-%d\")\n",
    "FP_end = dt.strptime(covid_clean_data['date'][len(covid_clean_data)-1], \"%Y-%m-%d\")\n",
    "\n",
    "#reindexing for weekly processing \n",
    "covid_clean_data['date'] = covid_clean_data['date'].astype('datetime64[ns]')\n",
    "covid_clean_data = covid_clean_data.set_index('date')\n",
    "\n",
    "#hospitalized increase is not useful in this context, so drop the column\n",
    "covid_clean_data = covid_clean_data.drop(['hospitalizedIncrease'], axis = 1)\n",
    "\n",
    "#dividing up into different time periods\n",
    "full_period = covid_clean_data\n",
    "\n",
    "early_breakout = covid_clean_data[EB_start:EB_end].reset_index(drop=True)\n",
    "\n",
    "summer = covid_clean_data[S_start:S_end].reset_index(drop=True)\n",
    "\n",
    "fall = covid_clean_data[FP_start:FP_end].reset_index(drop=True)\n",
    "\n",
    "#After dividing up the data into the periods, we can discretize into the k bins using the \"discretize_data\" function implemented earlier.\n",
    "discretize_data(full_period,10)\n",
    "discretize_data(early_breakout,8)\n",
    "discretize_data(summer,8)\n",
    "discretize_data(fall,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up state policy dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating data only about the current state of interest, California\n",
    "policy_clean_data = policy_data[policy_data['RegionName'] == 'California']\n",
    "#deleting rows whose dates are outside of the scope of this project\n",
    "policy_clean_data = policy_clean_data.iloc[60:] #delete the first 60 rows due to their January - February dates\n",
    "policy_clean_data = policy_clean_data.iloc[:-3,] #as well as the last 3 rows due to their December dates\n",
    "\n",
    "#declaring and extracting columns of interest from the original dataset\n",
    "columns_of_interest = ['Date', 'C1_School closing', 'C2_Workplace closing', \n",
    "                       'C3_Cancel public events', 'C4_Restrictions on gatherings', 'C6_Stay at home requirements', \n",
    "                       'C7_Restrictions on internal movement', 'C8_International travel controls', \n",
    "                       'H1_Public information campaigns', 'H2_Testing policy', 'H3_Contact tracing', \n",
    "                       'H4_Emergency investment in healthcare', \n",
    "                       'H6_Facial Coverings']\n",
    "policy_clean_data = policy_clean_data[columns_of_interest].fillna(0)\n",
    "\n",
    "# reformating date section and range of dates needed\n",
    "policy_clean_data = policy_clean_data.reset_index(drop = True)\n",
    "\n",
    "date_col = policy_clean_data['Date'].astype('str')\n",
    "for i in range(policy_clean_data.shape[0]):\n",
    "    date_col[i] = dt.strptime(date_col[i], \"%Y%m%d\")\n",
    "    \n",
    "policy_clean_data['Date'] = date_col\n",
    "\n",
    "start_date = dt.strptime('20200306', \"%Y%m%d\")\n",
    "end_date = dt.strptime('20201129', \"%Y%m%d\")\n",
    "\n",
    "policy_clean_data = policy_clean_data.rename(columns = {\"Date\": \"date\"})\n",
    "\n",
    "policy_clean_data = policy_clean_data.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing values of policy_clean_data to the type of policy each number corresponds to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C1_School closing\n",
    "policy_clean_data['C1_School closing'] = policy_clean_data['C1_School closing'].replace(0, 'no measures, school closing')\n",
    "policy_clean_data['C1_School closing'] = policy_clean_data['C1_School closing'].replace(1, 'recommend closing or all schools open with alterations resulting in significant differences compared to non-Covid-19 operations')\n",
    "policy_clean_data['C1_School closing'] = policy_clean_data['C1_School closing'].replace(2, 'require closing (only some levels or categories, eg just high school, or just public schools)')\n",
    "policy_clean_data['C1_School closing'] = policy_clean_data['C1_School closing'].replace(3, 'require closing all levels, school closing')\n",
    "#C2_Workplace closing\n",
    "policy_clean_data['C2_Workplace closing'] = policy_clean_data['C2_Workplace closing'].replace(0, 'no measures, workplace closing')\n",
    "policy_clean_data['C2_Workplace closing'] = policy_clean_data['C2_Workplace closing'].replace(1, 'recommend closing (or recommend work from home)')\n",
    "policy_clean_data['C2_Workplace closing'] = policy_clean_data['C2_Workplace closing'].replace(2, 'require closing (or work from home) for some sectors or categories of workers')\n",
    "policy_clean_data['C2_Workplace closing'] = policy_clean_data['C2_Workplace closing'].replace(3, 'require closing (or work from home) for all-but-essential workplaces (eg grocery stores, doctors)')\n",
    "#C3_Cancel public events\n",
    "policy_clean_data['C3_Cancel public events'] = policy_clean_data['C3_Cancel public events'].replace(0, 'no measures, cancel public events')\n",
    "policy_clean_data['C3_Cancel public events'] = policy_clean_data['C3_Cancel public events'].replace(1, 'recommend cancelling public events')\n",
    "policy_clean_data['C3_Cancel public events'] = policy_clean_data['C3_Cancel public events'].replace(2, 'require cancelling public events')\n",
    "#C4_Restrictions on gatherings                                                                                            \n",
    "policy_clean_data['C4_Restrictions on gatherings'] = policy_clean_data['C4_Restrictions on gatherings'].replace(0, 'no restrictions on gatherings')                                                                                              \n",
    "policy_clean_data['C4_Restrictions on gatherings'] = policy_clean_data['C4_Restrictions on gatherings'].replace(1, 'restrictions on very large gatherings (the limit is above 1000 people)')                                                                                              \n",
    "policy_clean_data['C4_Restrictions on gatherings'] = policy_clean_data['C4_Restrictions on gatherings'].replace(2, 'restrictions on gatherings between 101-1000 people')                                                                                              \n",
    "policy_clean_data['C4_Restrictions on gatherings'] = policy_clean_data['C4_Restrictions on gatherings'].replace(3, 'restrictions on gatherings between 11-100 people')                                                                                              \n",
    "policy_clean_data['C4_Restrictions on gatherings'] = policy_clean_data['C4_Restrictions on gatherings'].replace(4, 'restrictions on gatherings of 10 people or less')\n",
    "#C6_Stay at home requirements                                                                                            \n",
    "policy_clean_data['C6_Stay at home requirements'] = policy_clean_data['C6_Stay at home requirements'].replace(0, 'no measures for stay at home requirement')\n",
    "policy_clean_data['C6_Stay at home requirements'] = policy_clean_data['C6_Stay at home requirements'].replace(1, 'recommend not leaving house')\n",
    "policy_clean_data['C6_Stay at home requirements'] = policy_clean_data['C6_Stay at home requirements'].replace(2, 'require not leaving house with exceptions for daily exercise, grocery shopping, and \"essential\" trips')\n",
    "policy_clean_data['C6_Stay at home requirements'] = policy_clean_data['C6_Stay at home requirements'].replace(3, 'require not leaving house with minimal exceptions (eg allowed to leave once a week, or only one person can leave at a time, etc)')\n",
    "#C7_Restrictions on internal movement\n",
    "policy_clean_data['C7_Restrictions on internal movement'] = policy_clean_data['C7_Restrictions on internal movement'].replace(0, 'no measures on restrictions on internal movement')\n",
    "policy_clean_data['C7_Restrictions on internal movement'] = policy_clean_data['C7_Restrictions on internal movement'].replace(1, 'recommend not to travel between regions/cities')\n",
    "policy_clean_data['C7_Restrictions on internal movement'] = policy_clean_data['C7_Restrictions on internal movement'].replace(2, 'internal movement restrictions in place')\n",
    "#C8_International travel controls\n",
    "policy_clean_data['C8_International travel controls'] = policy_clean_data['C8_International travel controls'].replace(0, 'no restrictions on international travel')\n",
    "policy_clean_data['C8_International travel controls'] = policy_clean_data['C8_International travel controls'].replace(1, 'screening arrivals on international travel')\n",
    "policy_clean_data['C8_International travel controls'] = policy_clean_data['C8_International travel controls'].replace(2, 'quarantine arrivals from some or all regions for international travel')\n",
    "policy_clean_data['C8_International travel controls'] = policy_clean_data['C8_International travel controls'].replace(3, 'ban arrivals from some regions for international travel')\n",
    "policy_clean_data['C8_International travel controls'] = policy_clean_data['C8_International travel controls'].replace(4, 'ban on all regions or total border closure')\n",
    "#H1_Public information campaigns\n",
    "policy_clean_data['H1_Public information campaigns'] = policy_clean_data['H1_Public information campaigns'].replace(0, 'no Covid-19 public information campaign')\n",
    "policy_clean_data['H1_Public information campaigns'] = policy_clean_data['H1_Public information campaigns'].replace(1, 'public officials urging caution about Covid-19')\n",
    "policy_clean_data['H1_Public information campaigns'] = policy_clean_data['H1_Public information campaigns'].replace(2, 'coordinated public information campaign (eg across traditional and social media)')\n",
    "#H2_Testing policy\n",
    "policy_clean_data['H2_Testing policy'] = policy_clean_data['H2_Testing policy'].replace(0, 'no testing policy')\n",
    "policy_clean_data['H2_Testing policy'] = policy_clean_data['H2_Testing policy'].replace(1, 'only those who both (a) have symptoms AND (b) meet specific criteria (eg key workers, admitted to hospital, came into contact with a known case, returned from overseas)')\n",
    "policy_clean_data['H2_Testing policy'] = policy_clean_data['H2_Testing policy'].replace(2, 'testing of anyone showing Covid-19 symptoms')\n",
    "policy_clean_data['H2_Testing policy'] = policy_clean_data['H2_Testing policy'].replace(3, 'open public testing (eg \"drive through\" testing available to asymptomatic people)')\n",
    "#H3_Contact tracing\n",
    "policy_clean_data['H3_Contact tracing'] = policy_clean_data['H3_Contact tracing'].replace(0, 'no contact tracing')\n",
    "policy_clean_data['H3_Contact tracing'] = policy_clean_data['H3_Contact tracing'].replace(1, 'limited contact tracing; not done for all cases')\n",
    "policy_clean_data['H3_Contact tracing'] = policy_clean_data['H3_Contact tracing'].replace(2, 'comprehensive contact tracing; done for all identified cases')\n",
    "#H4_Emergency investment in healthcare\n",
    "### not a code, simply records the monetary value in USD\n",
    "policy_clean_data['H4_Emergency investment in healthcare'] = policy_clean_data['H4_Emergency investment in healthcare'].mask(policy_clean_data['H4_Emergency investment in healthcare'] > 0, 'investment')\n",
    "policy_clean_data['H4_Emergency investment in healthcare'] = policy_clean_data['H4_Emergency investment in healthcare'].replace(0, 'no new spending that day')\n",
    "\n",
    "#H6_Facial Coverings\n",
    "policy_clean_data['H6_Facial Coverings'] = policy_clean_data['H6_Facial Coverings'].replace(0, 'no policy on facial coverings')\n",
    "policy_clean_data['H6_Facial Coverings'] = policy_clean_data['H6_Facial Coverings'].replace(1, 'recommended facial coverings')\n",
    "policy_clean_data['H6_Facial Coverings'] = policy_clean_data['H6_Facial Coverings'].replace(2, 'facial coverings required in some specified shared/public spaces outside the home with other people present, or some situations when social distancing not possible')\n",
    "policy_clean_data['H6_Facial Coverings'] = policy_clean_data['H6_Facial Coverings'].replace(3, 'facial coverings required in all shared/public spaces outside the home with other people present or all situations when social distancing not possible')\n",
    "policy_clean_data['H6_Facial Coverings'] = policy_clean_data['H6_Facial Coverings'].replace(4, 'facial coverings required outside the home at all times regardless of location or presence of other people')\n",
    "                                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to drop some columns that skewed the Apriori results and didn't offer much info in general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_clean_data = policy_clean_data.drop(['H1_Public information campaigns','H4_Emergency investment in healthcare','H3_Contact tracing'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing up the policy data into the seperate periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_breakout_policy = policy_clean_data[EB_start:EB_end].reset_index(drop=True)\n",
    "\n",
    "summer_policy = policy_clean_data[S_start:S_end].reset_index(drop=True)\n",
    "\n",
    "fall_policy = policy_clean_data[FP_start:FP_end].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EB_C1 = early_breakout_policy[\"C1_School closing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging case and policy dataframes to create the basket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_basket_full = pd.merge(full_period, policy_clean_data,left_index = True, right_index = True)\n",
    "\n",
    "CA_basket_EB = pd.merge(early_breakout, early_breakout_policy,left_index = True, right_index = True)\n",
    "\n",
    "CA_basket_summer = pd.merge(summer, summer_policy,left_index = True, right_index = True)\n",
    "\n",
    "CA_basket_fall = pd.merge(fall, fall_policy,left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Important CA Stats:\n",
    "\n",
    "- Population (census.gov estimate): 39,512,223\n",
    "- Land Area (estimate): 163,696 sq. mi.\n",
    "- Population Density (statista.com): 253.9 people/sq. mi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pandemic Period\n",
    "\n",
    "#### All Policies Included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "#full pandemic period\n",
    "\n",
    "all_elements = CA_basket_full.values.tolist()\n",
    "flat_list = [item for sublist in all_elements for item in sublist]\n",
    "temp_df = pd.DataFrame({'col':flat_list})\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18, 7)\n",
    "color = plt.cm.copper(np.linspace(0, 1, 40))\n",
    "temp_df['col'].value_counts().head(40).plot.bar(color = color)\n",
    "plt.title('frequency of most popular \"items\" in CA', fontsize = 20)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_array_full = CA_basket_full.values\n",
    "basket_cols_full = CA_basket_full.columns\n",
    "te_full = TransactionEncoder()\n",
    "te_dataset_full = te_full.fit(basket_array_full).transform(basket_array_full)\n",
    "\n",
    "CA_te_basket_full = pd.DataFrame(te_dataset_full, columns = te_full.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full period\n",
    "\n",
    "CA_freq_itemsets_full = apriori(CA_te_basket_full, min_support=0.4, use_colnames=True)\n",
    "CA_freq_itemsets_full['length'] = CA_freq_itemsets_full['itemsets'].apply(lambda x: len(x))\n",
    "rules_full = association_rules(CA_freq_itemsets_full, metric=\"conviction\", min_threshold=0.3)\n",
    "rules_full[\"antecedent_len\"] = rules_full[\"antecedents\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_rules = rules_full[(rules_full['confidence'] >= 0.7) & (rules_full['conviction'] >= 3)]\n",
    "trimmed_rules.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Breakout/Spring Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early breakout period\n",
    "all_elements = CA_basket_EB.values.tolist()\n",
    "flat_list = [item for sublist in all_elements for item in sublist]\n",
    "temp_df = pd.DataFrame({'col':flat_list})\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18, 7)\n",
    "color = plt.cm.copper(np.linspace(0, 1, 40))\n",
    "temp_df['col'].value_counts().head(40).plot.bar(color = color)\n",
    "plt.title('frequency of most popular \"items\" in CA during Spring', fontsize = 20)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_array_EB = CA_basket_EB.values\n",
    "basket_cols_EB = CA_basket_EB.columns\n",
    "te_EB = TransactionEncoder()\n",
    "te_dataset_EB = te_EB.fit(basket_array_EB).transform(basket_array_EB)\n",
    "\n",
    "CA_te_basket_EB = pd.DataFrame(te_dataset_EB, columns = te_EB.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EB period\n",
    "\n",
    "CA_freq_itemsets_EB = apriori(CA_te_basket_EB, min_support=0.4, use_colnames=True)\n",
    "CA_freq_itemsets_EB['length'] = CA_freq_itemsets_EB['itemsets'].apply(lambda x: len(x))\n",
    "rules_EB = association_rules(CA_freq_itemsets_EB, metric=\"conviction\", min_threshold=0.3)\n",
    "rules_EB[\"antecedent_len\"] = rules_EB[\"antecedents\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_rules_EB = rules_EB[(rules_EB['confidence'] >= 0.7) & (rules_EB['conviction'] >= 3) & (rules_EB['support'] >= 0.6)]\n",
    "trimmed_rules_EB.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summer Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summer period\n",
    "\n",
    "all_elements = CA_basket_summer.values.tolist()\n",
    "flat_list = [item for sublist in all_elements for item in sublist]\n",
    "temp_df = pd.DataFrame({'col':flat_list})\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18, 7)\n",
    "color = plt.cm.copper(np.linspace(0, 1, 40))\n",
    "temp_df['col'].value_counts().head(40).plot.bar(color = color)\n",
    "plt.title('frequency of most popular \"items\" in CA during summer', fontsize = 20)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_array_summer = CA_basket_summer.values\n",
    "basket_cols_summer = CA_basket_summer.columns\n",
    "te_summer = TransactionEncoder()\n",
    "te_dataset_summer = te_summer.fit(basket_array_summer).transform(basket_array_summer)\n",
    "\n",
    "CA_te_basket_summer = pd.DataFrame(te_dataset_summer, columns = te_summer.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summer period\n",
    "\n",
    "CA_freq_itemsets_summer = apriori(CA_te_basket_summer, min_support=0.6, use_colnames=True)\n",
    "CA_freq_itemsets_summer['length'] = CA_freq_itemsets_summer['itemsets'].apply(lambda x: len(x))\n",
    "rules_summer = association_rules(CA_freq_itemsets_summer, metric=\"conviction\", min_threshold=0.3)\n",
    "rules_summer[\"antecedent_len\"] = rules_summer[\"antecedents\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_rules_summer = rules_summer[(rules_summer['confidence'] >= 0.7) & \n",
    "                                    (rules_summer['support'] >= 0.7) & \n",
    "                                    (rules_summer['conviction'] > 1) &\n",
    "                                    (rules_summer['lift'] > 1)]\n",
    "trimmed_rules_summer.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fall Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fall period\n",
    "\n",
    "all_elements = CA_basket_fall.values.tolist()\n",
    "flat_list = [item for sublist in all_elements for item in sublist]\n",
    "temp_df = pd.DataFrame({'col':flat_list})\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18, 7)\n",
    "color = plt.cm.copper(np.linspace(0, 1, 40))\n",
    "temp_df['col'].value_counts().head(40).plot.bar(color = color)\n",
    "plt.title('frequency of most popular \"items\" in CA during Fall', fontsize = 20)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_array_fall = CA_basket_fall.values\n",
    "basket_cols_fall = CA_basket_fall.columns\n",
    "te_fall = TransactionEncoder()\n",
    "te_dataset_fall = te_fall.fit(basket_array_fall).transform(basket_array_fall)\n",
    "\n",
    "CA_te_basket_fall = pd.DataFrame(te_dataset_fall, columns = te_fall.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_te_basket_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fall period\n",
    "\n",
    "CA_freq_itemsets_fall = apriori(CA_te_basket_fall, min_support=0.4, use_colnames=True)\n",
    "CA_freq_itemsets_fall['length'] = CA_freq_itemsets_fall['itemsets'].apply(lambda x: len(x))\n",
    "rules_fall = association_rules(CA_freq_itemsets_fall, metric=\"conviction\", min_threshold=0.3)\n",
    "rules_fall[\"antecedent_len\"] = rules_fall[\"antecedents\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can mine for associations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.to_csv(\"California.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
